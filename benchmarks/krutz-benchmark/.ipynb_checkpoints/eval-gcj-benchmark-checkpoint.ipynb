{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APSEC2019 Results\n",
    "\n",
    "Date: 2019-07-19\n",
    "\n",
    "Description: An analysis of the semantic clone detection capabilities of `doLLy` using the solutions of google code jam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.3 (default, Mar 27 2019, 09:23:15) \n",
      "[Clang 10.0.1 (clang-1001.0.46.3)]\n"
     ]
    }
   ],
   "source": [
    "# Check system version\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as font_manager\n",
    "import seaborn as sns\n",
    "\n",
    "# Graphics\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "mpl.rcParams['figure.figsize'] = (8,6)\n",
    "mpl.rcParams['font.family'] = 'SF Mono'\n",
    "mpl.rcParams.update({'font.size': 12})\n",
    "mpl.rcParams['axes.titlepad'] = 20 \n",
    "mpl.rcParams['axes.titlesize'] = 12\n",
    "mpl.rcParams['axes.labelpad'] = 10\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set(font_scale = 1.25)\n",
    "sns.set_style('ticks', {'font.family' : 'SF Mono', \n",
    "                        'axes.grid' : True, \n",
    "                        'grid.linestyle': 'dotted',\n",
    "                        'grid.color': '0.8'})\n",
    "sns.axes_style({'axes.grid' : 'True'})\n",
    "sns.set_palette(sns.color_palette(['Black']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "# create the ground truth file\n",
    "files = map(os.path.basename, glob.glob('../data/*.c'))\n",
    "pairs = pd.DataFrame(list(itertools.combinations(files, 2)), columns=['filename0', 'filename1'])\n",
    "def is_clone(row):\n",
    "    pset0 = row['filename0'].split('_')[0]\n",
    "    pset1 = row['filename1'].split('_')[0]\n",
    "    if pset0 == pset1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "pairs['clone'] = pairs.apply(is_clone, axis=1)\n",
    "\n",
    "\n",
    "# parse the doLLy csv files\n",
    "def parse_doLLy_csv(pairs, threshold):    \n",
    "    doLLy_pairs = pd.read_csv(f'doLLy/gcj-doLLy-{threshold}.csv')\n",
    "    doLLy_pairs[f'doLLy-{threshold}'] = True\n",
    "    doLLy_pairs = doLLy_pairs.rename(columns={'filename': 'filename0', 'filename.1': 'filename1'})\n",
    "    doLLy_pairs = doLLy_pairs[['filename0', 'filename1', f'doLLy-{threshold}']]\n",
    "    doLLy_pairs = doLLy_pairs.drop_duplicates()\n",
    "    doLLy_pairs_rev = doLLy_pairs.rename(columns={'filename0': 'filename1', 'filename1': 'filename0'})\n",
    "    doLLy_pairs = doLLy_pairs.append(doLLy_pairs_rev, sort=False)\n",
    "    pairs = pd.merge(pairs, doLLy_pairs, how='left', on=['filename0', 'filename1'], validate='1:m')\n",
    "    pairs = pairs.fillna(False)\n",
    "    return pairs\n",
    "pairs = parse_doLLy_csv(pairs, '0.30')\n",
    "pairs = parse_doLLy_csv(pairs, '0.40')\n",
    "pairs = parse_doLLy_csv(pairs, '0.50')\n",
    "pairs = parse_doLLy_csv(pairs, '0.60')\n",
    "\n",
    "\n",
    "# parse NiCad clone pairs\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def parse_NiCad_xml(pairs, threshold):\n",
    "    root = ET.parse(f'NiCad/gcj_functions-blind-clones-{threshold}.xml').getroot()\n",
    "    NiCad = []\n",
    "    for child in root:\n",
    "        if child.tag == 'clone':\n",
    "            pair = []\n",
    "            for source in child:\n",
    "                file = source.get('file')\n",
    "                file = os.path.basename(file)\n",
    "                file = file[:-8]\n",
    "                pair.append(file)\n",
    "            NiCad.append(pair)\n",
    "    NiCad_pairs = pd.DataFrame(NiCad, columns=['filename0', 'filename1']).drop_duplicates()\n",
    "    NiCad_pairs_rev = pd.DataFrame(NiCad, columns=['filename1', 'filename0']).drop_duplicates()\n",
    "    NiCad_pairs[f'NiCad-{threshold}'] = True\n",
    "    NiCad_pairs_rev[f'NiCad-{threshold}'] = True\n",
    "    NiCad_pairs = NiCad_pairs.append(NiCad_pairs_rev, sort=False)\n",
    "    pairs = pd.merge(pairs, NiCad_pairs[['filename0', 'filename1', f'NiCad-{threshold}']], how='left', on=['filename0', 'filename1'], validate='1:m')\n",
    "    pairs = pairs.fillna(False)\n",
    "    return pairs\n",
    "pairs = parse_NiCad_xml(pairs, '0.30')\n",
    "pairs = parse_NiCad_xml(pairs, '0.40')\n",
    "pairs = parse_NiCad_xml(pairs, '0.50')\n",
    "\n",
    "\n",
    "# parse CCCD clone pairs\n",
    "import re\n",
    "\n",
    "CCCD_pairs = pd.read_csv('CCCD/gcj_comparisionReport.csv')\n",
    "def parse_CCCD_files(files):\n",
    "    _, file0, file1 = re.split(r'gcj\\.(?=[\\w])', files)\n",
    "    file0 = file0.split('..')[0]\n",
    "    file1 = file1.split('..')[0]\n",
    "    return pd.Series([file0 + '.c', file1 + '.c'], index=['filename0', 'filename1'])\n",
    "    \n",
    "\n",
    "CCCD_pairs = CCCD_pairs.join(CCCD_pairs['Files'].apply(parse_CCCD_files))\n",
    "CCCD_pairs = CCCD_pairs.drop('Files', axis=1)\n",
    "\n",
    "CCCD_pairs = CCCD_pairs.groupby(['filename0', 'filename1']).min()\n",
    "CCCD_pairs = pd.DataFrame(CCCD_pairs.to_records())\n",
    "CCCD_pairs = CCCD_pairs.append(CCCD_pairs.rename(columns={\"filename0\": \"filename1\", \"filename1\": \"filename0\"}), sort=False).drop_duplicates()\n",
    "CCCD_pairs['CCCD-0.30'] = CCCD_pairs['LevenDistance'] <= 30.0\n",
    "CCCD_pairs['CCCD-0.40'] = CCCD_pairs['LevenDistance'] <= 40.0\n",
    "CCCD_pairs['CCCD-0.50'] = CCCD_pairs['LevenDistance'] <= 50.0\n",
    "pairs = pd.merge(pairs, CCCD_pairs[['CCCD-0.30', 'CCCD-0.40', 'CCCD-0.50', 'filename0', 'filename1']], how='left', on=['filename0', 'filename1'], validate='1:m').drop_duplicates(subset=['filename0','filename1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(tool, pairs):\n",
    "    tp = len(pairs[pairs[tool] & pairs['clone']])\n",
    "    fp = len(pairs[~pairs['clone'] & pairs[tool]])\n",
    "    tn = len(pairs[~pairs['clone'] & ~pairs[tool]])\n",
    "    fn = len(pairs[pairs['clone'] & ~pairs[tool]])\n",
    "\n",
    "    if fn == 0:\n",
    "        recall = 1.0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    if fp == 0:\n",
    "        precision = 1.0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "    if (precision + recall) == 0:\n",
    "        f1 = 0.0\n",
    "    else:\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    return [precision, recall, f1, accuracy, tp, fp, tn, fn]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &   tp &    fp &     tn &    fn \\\\\n",
      "\\midrule\n",
      "doLLy-0.50 &  296 &  1906 &  41594 &  1054 \\\\\n",
      "doLLy-0.40 &  130 &   527 &  42973 &  1220 \\\\\n",
      "doLLy-0.60 &  588 &  7340 &  36160 &   762 \\\\\n",
      "CCCD-0.40  &  119 &   923 &  42577 &  1231 \\\\\n",
      "CCCD-0.50  &  216 &  3836 &  39664 &  1134 \\\\\n",
      "doLLy-0.30 &   61 &   259 &  43241 &  1289 \\\\\n",
      "NiCad-0.50 &   47 &   365 &  43135 &  1303 \\\\\n",
      "CCCD-0.30  &   37 &   220 &  43280 &  1313 \\\\\n",
      "NiCad-0.40 &   20 &   177 &  43323 &  1330 \\\\\n",
      "NiCad-0.30 &    8 &    85 &  43415 &  1342 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pairs = pairs.replace(np.nan, False)\n",
    "results = [\n",
    "    confusion_matrix('doLLy-0.30', pairs),\n",
    "    confusion_matrix('doLLy-0.40', pairs),\n",
    "    confusion_matrix('doLLy-0.50', pairs),\n",
    "    confusion_matrix('doLLy-0.60', pairs),\n",
    "    confusion_matrix('NiCad-0.30', pairs),\n",
    "    confusion_matrix('NiCad-0.40', pairs),\n",
    "    confusion_matrix('NiCad-0.50', pairs),\n",
    "    confusion_matrix('CCCD-0.30', pairs),\n",
    "    confusion_matrix('CCCD-0.40', pairs),\n",
    "    confusion_matrix('CCCD-0.50', pairs),\n",
    "]\n",
    "results = pd.DataFrame(results, columns=['precision', 'recall', 'f1', 'accuracy', 'tp', 'fp', 'tn', 'fn'],\n",
    "                      index=['doLLy-0.30', 'doLLy-0.40', 'doLLy-0.50', 'doLLy-0.60',\n",
    "                             'NiCad-0.30', 'NiCad-0.40', 'NiCad-0.50',\n",
    "                             'CCCD-0.30', 'CCCD-0.40', 'CCCD-0.50'\n",
    "                            ])\n",
    "print(results.sort_values('f1', ascending=False).round(3)[['tp', 'fp', 'tn', 'fn']].to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "candidates to show case where doLLy detects a clone and NiCad does not:\n",
    "* oversized-pancake-flipper: mimo31 and Neelesh.Sinha\n",
    "* alphabet-cake: shikhar1997 and squeekeek\n",
    "* oversized-pancake-flipper: helloneo.pe.kr and algmyr\n",
    "* mushroom-monster: syuxuan and maups\n",
    "* alphabet-cake: Ioannis70 and lemmaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doLLy vs CCCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  precision &  recall &     f1 &  accuracy \\\\\n",
      "\\midrule\n",
      "doLLy-0.50 &      0.132 &   0.239 &  0.170 &     0.930 \\\\\n",
      "doLLy-0.40 &      0.209 &   0.109 &  0.144 &     0.961 \\\\\n",
      "CCCD-0.40  &      0.114 &   0.191 &  0.143 &     0.920 \\\\\n",
      "doLLy-0.60 &      0.074 &   0.465 &  0.128 &     0.810 \\\\\n",
      "CCCD-0.30  &      0.144 &   0.069 &  0.093 &     0.958 \\\\\n",
      "CCCD-0.50  &      0.053 &   0.300 &  0.091 &     0.792 \\\\\n",
      "doLLy-0.30 &      0.135 &   0.038 &  0.059 &     0.964 \\\\\n",
      "NiCad-0.50 &      0.062 &   0.030 &  0.040 &     0.958 \\\\\n",
      "NiCad-0.40 &      0.054 &   0.012 &  0.020 &     0.964 \\\\\n",
      "NiCad-0.30 &      0.000 &   0.000 &  0.000 &     0.966 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pair_subset = pairs[~pd.isnull(pairs['CCCD-0.50'])]\n",
    "results = [\n",
    "    confusion_matrix('doLLy-0.30', pair_subset),\n",
    "    confusion_matrix('doLLy-0.40', pair_subset),\n",
    "    confusion_matrix('doLLy-0.50', pair_subset),\n",
    "    confusion_matrix('doLLy-0.60', pair_subset),\n",
    "    confusion_matrix('NiCad-0.30', pair_subset),\n",
    "    confusion_matrix('NiCad-0.40', pair_subset),\n",
    "    confusion_matrix('NiCad-0.50', pair_subset),\n",
    "    confusion_matrix('CCCD-0.30', pair_subset),\n",
    "    confusion_matrix('CCCD-0.40', pair_subset),\n",
    "    confusion_matrix('CCCD-0.50', pair_subset),\n",
    "]\n",
    "results = pd.DataFrame(results, columns=['precision', 'recall', 'f1', 'accuracy'],\n",
    "                      index=['doLLy-0.30', 'doLLy-0.40', 'doLLy-0.50', 'doLLy-0.60',\n",
    "                             'NiCad-0.30', 'NiCad-0.40', 'NiCad-0.50',\n",
    "                             'CCCD-0.30', 'CCCD-0.40', 'CCCD-0.50'])\n",
    "print(results.sort_values('f1', ascending=False).round(3).to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
